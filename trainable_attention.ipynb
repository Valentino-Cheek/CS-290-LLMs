{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7c33a1a1",
      "metadata": {
        "id": "7c33a1a1"
      },
      "source": [
        "# Attention with trainable weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 591,
      "id": "c78b079a",
      "metadata": {
        "id": "c78b079a"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 592,
      "id": "d1c0c81b",
      "metadata": {
        "id": "d1c0c81b"
      },
      "outputs": [],
      "source": [
        "inputs = torch.nn.Embedding( 4, 8 )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = inputs.weight.data\n",
        "inputs"
      ],
      "metadata": {
        "id": "EGWp0DcrxAYS",
        "outputId": "a64209a2-ac40-44dc-e8c8-a1355d0e4375",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "EGWp0DcrxAYS",
      "execution_count": 593,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.0533,  0.1388, -0.2044, -2.2685, -0.9133, -0.4204,  1.3111, -0.2199],\n",
              "        [ 0.1838,  0.2293,  0.6177, -0.2876,  0.8218,  0.1512,  0.1036, -2.1996],\n",
              "        [-2.3229,  1.0878, -0.0635, -0.4486, -1.2785, -1.1440,  0.2436, -0.0567],\n",
              "        [ 0.4403, -1.4465, -0.5581, -0.0517, -0.9083,  0.3507,  1.5434,  0.1406]])"
            ]
          },
          "metadata": {},
          "execution_count": 593
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set dimension\n",
        "d_in = 8\n",
        "d_out = 6\n",
        "\n",
        "# create weight matrices\n",
        "w_query = torch.nn.Parameter( torch.randn( d_in, d_out ), requires_grad=False )\n",
        "w_key = torch.nn.Parameter( torch.randn( d_in, d_out ), requires_grad=False )\n",
        "w_value = torch.nn.Parameter( torch.randn( d_in, d_out ), requires_grad=False )\n"
      ],
      "metadata": {
        "id": "BV1AyTvYxCt8"
      },
      "id": "BV1AyTvYxCt8",
      "execution_count": 594,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# choose and input vector and tranfrom it into our query vector using w_query\n",
        "query = inputs[2] @ w_query\n",
        "query"
      ],
      "metadata": {
        "id": "giMsI6IoyWTl",
        "outputId": "67ae56fa-8744-4d00-84b5-be3c95777fe9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "giMsI6IoyWTl",
      "execution_count": 595,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.4048,  5.5231, -2.0989, -1.6392, -2.1866,  2.1391])"
            ]
          },
          "metadata": {},
          "execution_count": 595
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate attention scores using the keys generated by w_key\n",
        "keys = inputs @ w_key\n",
        "values = inputs @ w_value\n",
        "print(\"Values: \", values, \"\\nKeys: \", keys)"
      ],
      "metadata": {
        "id": "6C8AR2qzy3MI",
        "outputId": "cb4c417d-3f2c-4aa9-847e-c84cc01d7b76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "6C8AR2qzy3MI",
      "execution_count": 596,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Values:  tensor([[ 4.0310, -0.1499,  1.7580,  3.0791, -1.6066, -0.5806],\n",
            "        [ 3.8501,  1.1053, -2.9978, -2.0425,  0.4336, -0.8436],\n",
            "        [-3.7869, -1.9328,  1.8063,  0.6338, -3.7921, -1.2053],\n",
            "        [ 1.7406,  1.1961, -0.9290,  0.2997, -0.7902,  2.6447]]) \n",
            "Keys:  tensor([[ 2.6992, -3.4495, -4.9359, -5.9429, -1.5600,  1.5451],\n",
            "        [ 0.7882, -5.2803,  0.1594,  0.2066,  1.0121, -0.5606],\n",
            "        [ 2.9669,  0.1861,  1.8968, -1.0446, -5.5319,  6.1505],\n",
            "        [-0.7256, -0.5183, -0.9423, -2.1783,  2.1761,  2.1374]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_scores = query @ keys.T\n",
        "attention_scores"
      ],
      "metadata": {
        "id": "dbIXaFAuzI8-",
        "outputId": "a1dd767d-0b39-443c-f849-85ccce4543d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "dbIXaFAuzI8-",
      "execution_count": 597,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 11.5579, -32.1414,  28.1797,   1.4804])"
            ]
          },
          "metadata": {},
          "execution_count": 597
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# attention_weights = attention_scores.softmax(dim = -1)\n",
        "\n",
        "attention_weights = torch.softmax(attention_scores / keys.shape[-1]**0.5, dim=-1 )\n",
        "attention_weights"
      ],
      "metadata": {
        "id": "ZojH88rW0FUZ",
        "outputId": "d0188f8d-9cb9-46c6-b228-84f5550d4900",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ZojH88rW0FUZ",
      "execution_count": 598,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.1283e-03, 2.0163e-11, 9.9885e-01, 1.8438e-05])"
            ]
          },
          "metadata": {},
          "execution_count": 598
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights.sum()"
      ],
      "metadata": {
        "id": "K7y_eHzk0hrh",
        "outputId": "ffe13a0f-d157-46cc-c0bf-6e8d4d2f7590",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "K7y_eHzk0hrh",
      "execution_count": 599,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {},
          "execution_count": 599
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_vector = attention_weights @ values\n",
        "context_vector"
      ],
      "metadata": {
        "id": "QcX7_Lr407D2",
        "outputId": "88ae8c3b-48ac-4788-8e8a-982bfe65bba6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "QcX7_Lr407D2",
      "execution_count": 600,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-3.7779, -1.9307,  1.8062,  0.6366, -3.7895, -1.2045])"
            ]
          },
          "metadata": {},
          "execution_count": 600
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "9CJK6c8p090W"
      },
      "id": "9CJK6c8p090W",
      "execution_count": 601,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleAttention( nn.Module ):\n",
        "  def __init__( self, d_in, d_out ):\n",
        "    super().__init__()\n",
        "    # create weight matrices\n",
        "    self.W_query = torch.nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
        "    self.W_key = torch.nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
        "    self.W_value = torch.nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
        "\n",
        "  # x = embedding vectors (inputs)\n",
        "  def forward(self, x):\n",
        "    query = x @ self.W_query\n",
        "    keys = x @ self.W_key\n",
        "    values = x @ self.W_value\n",
        "    attention_scores = query @ keys.T\n",
        "    weights = torch.softmax(attention_scores / keys.shape[-1]**0.5, dim=-1 )\n",
        "    context_vector = weights @ values\n",
        "    return context_vector\n",
        "\n"
      ],
      "metadata": {
        "id": "rmqohDO9EwKF"
      },
      "id": "rmqohDO9EwKF",
      "execution_count": 602,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# how to use, instantiate an instance of it\n",
        "simple = SimpleAttention( d_in=8, d_out=6 )"
      ],
      "metadata": {
        "id": "8dPmmHSkGedw"
      },
      "id": "8dPmmHSkGedw",
      "execution_count": 603,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simple.W_value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLWq9QVCGjbt",
        "outputId": "d3b4671b-3f28-46b8-bb09-028c74848970"
      },
      "id": "sLWq9QVCGjbt",
      "execution_count": 604,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[0.7355, 0.6248, 0.1638, 0.5158, 0.6000, 0.2299],\n",
              "        [0.2890, 0.9078, 0.4596, 0.4947, 0.1836, 0.2010],\n",
              "        [0.9603, 0.6861, 0.4209, 0.8046, 0.2621, 0.0638],\n",
              "        [0.0036, 0.7032, 0.3051, 0.8070, 0.9271, 0.6647],\n",
              "        [0.9296, 0.3848, 0.9357, 0.2616, 0.4344, 0.8323],\n",
              "        [0.2410, 0.8815, 0.6226, 0.4902, 0.9279, 0.8751],\n",
              "        [0.2943, 0.5485, 0.5583, 0.9096, 0.7810, 0.9049],\n",
              "        [0.8048, 0.0649, 0.8322, 0.3672, 0.9012, 0.8146]])"
            ]
          },
          "metadata": {},
          "execution_count": 604
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_vectors = simple(inputs)\n",
        "context_vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fo3YvoTGmDf",
        "outputId": "7b66036e-04b1-4640-f806-3e1642b38806"
      },
      "id": "5fo3YvoTGmDf",
      "execution_count": 605,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.8343, -2.1591, -1.8431, -1.7378, -3.0583, -2.4742],\n",
              "        [-0.8974, -0.6558, -0.8224, -0.1684, -0.4084, -0.3660],\n",
              "        [-2.8581, -2.1767, -1.8535, -1.7533, -3.0820, -2.4929],\n",
              "        [-1.7793, -1.3494, -1.4022, -1.0888, -2.1340, -1.7414]])"
            ]
          },
          "metadata": {},
          "execution_count": 605
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleAttention2( nn.Module ):\n",
        "  def __init__( self, d_in, d_out ):\n",
        "    super().__init__()\n",
        "    # create weight matrices\n",
        "    self.W_query = nn.Linear( d_in, d_out, bias=False )\n",
        "    self.W_key = nn.Linear( d_in, d_out, bias=False )\n",
        "    self.W_value = nn.Linear( d_in, d_out, bias=False )\n",
        "\n",
        "  # x = embedding vectors (inputs)\n",
        "  def forward(self, x):\n",
        "    query = self.W_query( x )\n",
        "    keys = self.W_key( x )\n",
        "    values = self.W_value( x )\n",
        "    attention_scores = query @ keys.T\n",
        "    weights = torch.softmax(attention_scores / keys.shape[-1]**0.5, dim=-1 )\n",
        "    context_vector = weights @ values\n",
        "    return context_vector"
      ],
      "metadata": {
        "id": "jkfLRAbqGyZ9"
      },
      "id": "jkfLRAbqGyZ9",
      "execution_count": 606,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# how to use, instantiate an instance of it\n",
        "simple = SimpleAttention2( d_in=8, d_out=6 )\n"
      ],
      "metadata": {
        "id": "f7MsCXlAIsAO"
      },
      "id": "f7MsCXlAIsAO",
      "execution_count": 607,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simple.W_value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sChX5MKRIvD-",
        "outputId": "b0c8e4a6-1f18-4d1b-a66e-8a342a484395"
      },
      "id": "sChX5MKRIvD-",
      "execution_count": 608,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=8, out_features=6, bias=False)"
            ]
          },
          "metadata": {},
          "execution_count": 608
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_vectors = simple(inputs)\n",
        "context_vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ETDYdLZI2QN",
        "outputId": "9f828f5c-58a0-4c29-bf4f-f0a059083fbf"
      },
      "id": "_ETDYdLZI2QN",
      "execution_count": 609,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5.6137e-01,  2.3243e-01,  1.2150e-01, -1.9756e-01,  4.7015e-01,\n",
              "          1.5979e-01],\n",
              "        [ 6.0625e-01,  2.6822e-01,  1.9601e-01, -2.0487e-01,  3.3184e-01,\n",
              "          7.4284e-02],\n",
              "        [ 4.7718e-01,  1.8690e-01, -3.9953e-04, -1.8236e-01,  5.9303e-01,\n",
              "          2.5653e-01],\n",
              "        [ 4.2967e-01,  1.5835e-01,  3.3162e-03, -1.5923e-01,  4.1212e-01,\n",
              "          1.4546e-01]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 609
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the problem wit h this is that each context vector uses infortmation from ALL of the embedding vectors\n",
        "# om practice, wer should only use the information about the preceding embedding vectors\n",
        "# to accomplish this, we'll implement causal attention AKA masked attention"
      ],
      "metadata": {
        "id": "HYxGgL0dI3sP"
      },
      "id": "HYxGgL0dI3sP",
      "execution_count": 610,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleAttention2( nn.Module ):\n",
        "  def __init__( self, d_in, d_out ):\n",
        "    super().__init__()\n",
        "    # create weight matrices\n",
        "    self.W_query = nn.Linear( d_in, d_out, bias=False )\n",
        "    self.W_key = nn.Linear( d_in, d_out, bias=False )\n",
        "    self.W_value = nn.Linear( d_in, d_out, bias=False )\n",
        "\n",
        "  # x = embedding vectors (inputs)\n",
        "  def forward(self, x):\n",
        "    query = self.W_query( x )\n",
        "    keys = self.W_key( x )\n",
        "    values = self.W_value( x )\n",
        "    attention_scores = query @ keys.T\n",
        "    weights = torch.softmax(attention_scores / keys.shape[-1]**0.5, dim=-1 )\n",
        "    context_vector = weights @ values\n",
        "    return weights"
      ],
      "metadata": {
        "id": "yihDtot8dTLs"
      },
      "id": "yihDtot8dTLs",
      "execution_count": 611,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simple = SimpleAttention2( d_in=8, d_out=6 )\n",
        "weights = simple( inputs )\n",
        "weights"
      ],
      "metadata": {
        "id": "GQavVLtQditY",
        "outputId": "caed90e7-2f90-4115-f486-8b44520aea4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "GQavVLtQditY",
      "execution_count": 612,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2708, 0.2100, 0.2373, 0.2819],\n",
              "        [0.2025, 0.2152, 0.3724, 0.2099],\n",
              "        [0.2983, 0.2595, 0.1685, 0.2737],\n",
              "        [0.2575, 0.1819, 0.3239, 0.2367]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 612
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#already normalized\n",
        "weights.sum(dim= -1)"
      ],
      "metadata": {
        "id": "YhQ2lau0dr0X",
        "outputId": "c54bd390-c106-4d76-ebcc-b05c80e47238",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "YhQ2lau0dr0X",
      "execution_count": 613,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1.], grad_fn=<SumBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 613
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Masking Method 1\n",
        "simple_mask = torch.tril( torch.ones(weights.shape[0],weights.shape[0]))\n",
        "simple_mask"
      ],
      "metadata": {
        "id": "yI4jQ5Xrd_3B",
        "outputId": "231a1ca3-9456-40fc-d514-1481aa44b598",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "yI4jQ5Xrd_3B",
      "execution_count": 614,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0.],\n",
              "        [1., 1., 0., 0.],\n",
              "        [1., 1., 1., 0.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 614
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# multiply to get the coordinate by coordinate product, NOT dot product\n",
        "masked_weights = weights * simple_mask\n",
        "masked_weights"
      ],
      "metadata": {
        "id": "DFwEX_i0eq_6",
        "outputId": "3f3dd62d-7557-411b-db4b-4f5572899773",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "DFwEX_i0eq_6",
      "execution_count": 615,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2708, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2025, 0.2152, 0.0000, 0.0000],\n",
              "        [0.2983, 0.2595, 0.1685, 0.0000],\n",
              "        [0.2575, 0.1819, 0.3239, 0.2367]], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 615
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now we need to normaliz the masked_weights so that each row has a sum 1\n",
        "row_sums = masked_weights.sum(dim=-1, keepdim=True)\n",
        "row_sums"
      ],
      "metadata": {
        "id": "8JxuevCRe8XI",
        "outputId": "4b11e838-5bb1-4aa5-99bd-272edf800c9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "8JxuevCRe8XI",
      "execution_count": 616,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2708],\n",
              "        [0.4177],\n",
              "        [0.7263],\n",
              "        [1.0000]], grad_fn=<SumBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 616
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_weights_norm = masked_weights / row_sums\n",
        "print(masked_weights_norm)\n",
        "print(masked_weights_norm.sum(dim=-1))"
      ],
      "metadata": {
        "id": "D5KVzCecfvrX",
        "outputId": "be1b01b8-93f8-4951-f169-88cb9f694d42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "D5KVzCecfvrX",
      "execution_count": 617,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.4848, 0.5152, 0.0000, 0.0000],\n",
            "        [0.4107, 0.3573, 0.2320, 0.0000],\n",
            "        [0.2575, 0.1819, 0.3239, 0.2367]], grad_fn=<DivBackward0>)\n",
            "tensor([1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Masking method 2\n",
        "mask = torch.triu(torch.ones(weights.shape[0], weights.shape[0]), diagonal =1)\n",
        "mask"
      ],
      "metadata": {
        "id": "nB_aMu4df3WP",
        "outputId": "bfe8b037-2ebf-47a7-f95e-0f7ed9f9f495",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "nB_aMu4df3WP",
      "execution_count": 618,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1., 1., 1.],\n",
              "        [0., 0., 1., 1.],\n",
              "        [0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 618
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# can use mask == 1 or mask.bool()\n",
        "weights_masked = weights.masked_fill(mask == 1, -torch.inf)\n",
        "weights_masked"
      ],
      "metadata": {
        "id": "S5vi0z2PhDzI",
        "outputId": "8af28f86-bb97-43da-b18c-a518cc66277e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "S5vi0z2PhDzI",
      "execution_count": 619,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2708,   -inf,   -inf,   -inf],\n",
              "        [0.2025, 0.2152,   -inf,   -inf],\n",
              "        [0.2983, 0.2595, 0.1685,   -inf],\n",
              "        [0.2575, 0.1819, 0.3239, 0.2367]], grad_fn=<MaskedFillBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 619
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights_masked_norm = torch.softmax(weights_masked, dim=-1)\n",
        "weights_masked_norm\n",
        "print(weights_masked_norm.sum(dim=-1))"
      ],
      "metadata": {
        "id": "UTzLv__ahfKq",
        "outputId": "c21caccb-b8c7-4d12-9d5c-f05c89cb727d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "UTzLv__ahfKq",
      "execution_count": 620,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## DROPOUT - avoiding overfitting by randomly leaving out data\n",
        "# idea : randomly select some data to leave out to avoid overfitting\n",
        "dropout = nn.Dropout(p=0.5) # 50% dropout weight\n",
        "dropout( inputs )"
      ],
      "metadata": {
        "id": "46w4BDdMkWjf",
        "outputId": "a954afb2-6b68-4a9b-e038-8f9cfc69ddcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "46w4BDdMkWjf",
      "execution_count": 621,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.2776, -0.0000, -4.5371, -0.0000, -0.8407,  0.0000, -0.4399],\n",
              "        [ 0.3677,  0.4587,  0.0000, -0.5752,  0.0000,  0.0000,  0.2073, -0.0000],\n",
              "        [-0.0000,  0.0000, -0.1271, -0.8973, -0.0000, -2.2880,  0.0000, -0.1135],\n",
              "        [ 0.0000, -0.0000, -0.0000, -0.0000, -0.0000,  0.7014,  0.0000,  0.2812]])"
            ]
          },
          "metadata": {},
          "execution_count": 621
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we need to be able to give our LLM batches of input\n",
        "# for example:\n",
        "batches = torch.stack((inputs, inputs), dim=0)\n",
        "print(batches)\n",
        "# torch.stack?"
      ],
      "metadata": {
        "id": "DF4op0SbjUsJ",
        "outputId": "84995b27-0391-4662-c730-888d205f432f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "DF4op0SbjUsJ",
      "execution_count": 622,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 1.0533,  0.1388, -0.2044, -2.2685, -0.9133, -0.4204,  1.3111,\n",
            "          -0.2199],\n",
            "         [ 0.1838,  0.2293,  0.6177, -0.2876,  0.8218,  0.1512,  0.1036,\n",
            "          -2.1996],\n",
            "         [-2.3229,  1.0878, -0.0635, -0.4486, -1.2785, -1.1440,  0.2436,\n",
            "          -0.0567],\n",
            "         [ 0.4403, -1.4465, -0.5581, -0.0517, -0.9083,  0.3507,  1.5434,\n",
            "           0.1406]],\n",
            "\n",
            "        [[ 1.0533,  0.1388, -0.2044, -2.2685, -0.9133, -0.4204,  1.3111,\n",
            "          -0.2199],\n",
            "         [ 0.1838,  0.2293,  0.6177, -0.2876,  0.8218,  0.1512,  0.1036,\n",
            "          -2.1996],\n",
            "         [-2.3229,  1.0878, -0.0635, -0.4486, -1.2785, -1.1440,  0.2436,\n",
            "          -0.0567],\n",
            "         [ 0.4403, -1.4465, -0.5581, -0.0517, -0.9083,  0.3507,  1.5434,\n",
            "           0.1406]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batches.shape"
      ],
      "metadata": {
        "id": "diGeJ_Wbj4OO",
        "outputId": "1b733095-5ddb-40d3-88fa-4bae2ba446c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "diGeJ_Wbj4OO",
      "execution_count": 623,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 4, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 623
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # this class needs to hand batches of input\n",
        "\n",
        "# class CausalAttention( nn.Module ) :\n",
        "#   def __init__( self, d_in, d_out, context_length, dropout, qky_bias=False ):\n",
        "#     super().__init__()\n",
        "#     # create weight matrices\n",
        "#     self.W_query = nn.Linear( d_in, d_out, bias=False )\n",
        "#     self.W_key = nn.Linear( d_in, d_out, bias=False )\n",
        "#     self.W_value = nn.Linear( d_in, d_out, bias=False )\n",
        "#     self.dropout = nn.Dropout( dropout )\n",
        "\n",
        "#   # x = embedding vectors (inputs)\n",
        "#   def forward(self, x):\n",
        "#     query = self.W_query( x )\n",
        "#     keys = self.W_key( x )\n",
        "#     values = self.W_value( x )\n",
        "#     attention_scores = query @ keys.T\n",
        "#     weights = torch.softmax(attention_scores / keys.shape[-1]**0.5, dim=-1 )\n",
        "#     context_vector = weights @ values\n",
        "#     return context_vector"
      ],
      "metadata": {
        "id": "k2OzXqWFiGun"
      },
      "id": "k2OzXqWFiGun",
      "execution_count": 624,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this class needs to handle batches of input!\n",
        "\n",
        "class CausalAttention( nn.Module ):\n",
        "  def __init__(self, d_in, d_out, context_length, dropout, qkv_bias=False):\n",
        "    super().__init__()\n",
        "    self.d_out = d_out\n",
        "    # create weight matrices:\n",
        "    self.W_q = nn.Linear( d_in, d_out, bias=False )\n",
        "    self.W_k = nn.Linear( d_in, d_out, bias=False )\n",
        "    self.W_v = nn.Linear( d_in, d_out, bias=False )\n",
        "    # include dropout:\n",
        "    self.dropout = nn.Dropout( dropout )\n",
        "    # use the following to manage memory efficiently:\n",
        "    self.register_buffer(\n",
        "        'mask',\n",
        "        torch.triu( torch.ones(context_length, context_length), diagonal = 1 )\n",
        "    )\n",
        "\n",
        "  # x = embedding vectors (inputs)\n",
        "  def forward( self, x ):\n",
        "    b, num_tokens, d_in = x.shape\n",
        "    queries = self.W_q( x )\n",
        "    keys = self.W_k( x )\n",
        "    values = self.W_v( x )\n",
        "    scores = queries @ keys.transpose(1,2)\n",
        "    scores.masked_fill_(self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)\n",
        "    weights = torch.softmax( scores / keys.shape[-1]**0.5, dim = -1 )\n",
        "    weights = self.dropout( weights )\n",
        "    context = weights @ values\n",
        "    return context"
      ],
      "metadata": {
        "id": "yw5zZJjkgNUW"
      },
      "id": "yw5zZJjkgNUW",
      "execution_count": 625,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate a causal attention mechanism:\n",
        "causal = CausalAttention( d_in=8, d_out=6, context_length=4, dropout=0 )"
      ],
      "metadata": {
        "id": "NOEZPrJngPd_"
      },
      "id": "NOEZPrJngPd_",
      "execution_count": 626,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "causal( batches )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1LAcBKRgR6Y",
        "outputId": "621a4b8e-940c-4755-e8df-6c1b2ec57d40"
      },
      "id": "Y1LAcBKRgR6Y",
      "execution_count": 627,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.1295,  0.7283, -1.0537,  0.5340, -0.4069, -1.0032],\n",
              "         [-0.4305,  0.0564, -0.2973,  0.0053, -0.0448,  0.0306],\n",
              "         [ 0.3387,  0.0275, -0.2099, -0.1538, -0.3687, -0.1400],\n",
              "         [ 0.0866,  0.2247, -0.1328,  0.0500, -0.2527, -0.2858]],\n",
              "\n",
              "        [[ 0.1295,  0.7283, -1.0537,  0.5340, -0.4069, -1.0032],\n",
              "         [-0.4305,  0.0564, -0.2973,  0.0053, -0.0448,  0.0306],\n",
              "         [ 0.3387,  0.0275, -0.2099, -0.1538, -0.3687, -0.1400],\n",
              "         [ 0.0866,  0.2247, -0.1328,  0.0500, -0.2527, -0.2858]]],\n",
              "       grad_fn=<UnsafeViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 627
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# heres the first pass of multiheaded attention\n",
        "class MultiHeadAtttention ( nn.Module ):\n",
        "  def __init__( self, d_in, d_out, num_heads, context_length, dropout, qkv_bias=False ):\n",
        "    super().__init__()\n",
        "    self.heads = nn.ModuleList(\n",
        "      [ CausalAttention( d_in, d_out, context_length, dropout, qkv_bias ) for _ in range( num_heads ) ]\n",
        "    )\n",
        "  def forward( self, x ):\n",
        "    return torch.cat( [head(x) for head in self.heads] , dim=-1 )"
      ],
      "metadata": {
        "id": "SjgWtSwvgvcR"
      },
      "id": "SjgWtSwvgvcR",
      "execution_count": 628,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mha = MultiHeadAtttention( d_in=8, d_out=6, num_heads=4, context_length=4, dropout=0 )"
      ],
      "metadata": {
        "id": "CIkdONC_g4IQ"
      },
      "id": "CIkdONC_g4IQ",
      "execution_count": 629,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ad1f5e0",
        "outputId": "a0b6f963-619c-4f45-b8b4-d19217aea899"
      },
      "source": [
        "mha_out = mha( batches )\n",
        "mha_out"
      ],
      "id": "1ad1f5e0",
      "execution_count": 630,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 5.5415e-02,  6.9044e-01, -5.0947e-01, -1.0197e-01,  1.0220e+00,\n",
              "           2.3957e-01, -6.1575e-01, -5.1908e-01,  8.1423e-01,  2.5077e-01,\n",
              "           8.6917e-01, -1.4233e-01, -2.9188e-01, -4.5756e-01, -6.3211e-01,\n",
              "           1.0346e-01, -1.0247e-01, -1.1738e+00, -1.2562e-01,  1.1179e+00,\n",
              "          -4.0048e-01,  1.8521e-01,  4.7765e-01,  9.9035e-01],\n",
              "         [-4.4370e-01,  5.9249e-02, -6.1015e-01, -1.6997e-01,  5.8622e-01,\n",
              "           2.2276e-01, -3.8214e-01, -1.0437e-01,  6.9650e-01,  3.9591e-02,\n",
              "           7.8057e-01,  2.3940e-01,  1.9300e-01,  5.0624e-02, -6.4491e-01,\n",
              "          -1.1939e-01, -1.3995e-01, -8.7192e-01,  7.0109e-02,  4.4353e-01,\n",
              "          -4.2574e-03, -4.8048e-01,  1.8570e-01,  1.6159e-01],\n",
              "         [-2.0398e-01,  3.1655e-01, -7.3651e-01,  6.3688e-02,  6.5674e-01,\n",
              "           2.3183e-01, -1.5374e-01, -1.7352e-01,  2.4260e-01, -1.6717e-01,\n",
              "           6.4879e-01,  2.7125e-02, -1.8632e-01,  2.0006e-01, -5.4526e-01,\n",
              "           1.2717e-01,  1.0821e-02, -2.6455e-01, -2.6858e-01,  3.5453e-01,\n",
              "           7.0066e-02, -4.6697e-01, -3.7250e-02, -1.7825e-02],\n",
              "         [-2.5842e-01, -1.5879e-03, -7.3816e-01,  3.3992e-04,  4.0950e-01,\n",
              "           6.5276e-02, -1.1635e-01, -1.8201e-01,  4.1028e-01, -2.1705e-01,\n",
              "           6.0742e-01, -2.0792e-02, -1.8707e-01, -2.1038e-01, -2.8120e-01,\n",
              "           2.1816e-01, -1.1572e-01, -5.2761e-01, -2.0959e-01,  3.1214e-01,\n",
              "          -1.3301e-01, -2.4530e-01,  7.6284e-02, -6.1614e-02]],\n",
              "\n",
              "        [[ 5.5415e-02,  6.9044e-01, -5.0947e-01, -1.0197e-01,  1.0220e+00,\n",
              "           2.3957e-01, -6.1575e-01, -5.1908e-01,  8.1423e-01,  2.5077e-01,\n",
              "           8.6917e-01, -1.4233e-01, -2.9188e-01, -4.5756e-01, -6.3211e-01,\n",
              "           1.0346e-01, -1.0247e-01, -1.1738e+00, -1.2562e-01,  1.1179e+00,\n",
              "          -4.0048e-01,  1.8521e-01,  4.7765e-01,  9.9035e-01],\n",
              "         [-4.4370e-01,  5.9249e-02, -6.1015e-01, -1.6997e-01,  5.8622e-01,\n",
              "           2.2276e-01, -3.8214e-01, -1.0437e-01,  6.9650e-01,  3.9591e-02,\n",
              "           7.8057e-01,  2.3940e-01,  1.9300e-01,  5.0624e-02, -6.4491e-01,\n",
              "          -1.1939e-01, -1.3995e-01, -8.7192e-01,  7.0109e-02,  4.4353e-01,\n",
              "          -4.2574e-03, -4.8048e-01,  1.8570e-01,  1.6159e-01],\n",
              "         [-2.0398e-01,  3.1655e-01, -7.3651e-01,  6.3688e-02,  6.5674e-01,\n",
              "           2.3183e-01, -1.5374e-01, -1.7352e-01,  2.4260e-01, -1.6717e-01,\n",
              "           6.4879e-01,  2.7125e-02, -1.8632e-01,  2.0006e-01, -5.4526e-01,\n",
              "           1.2717e-01,  1.0821e-02, -2.6455e-01, -2.6858e-01,  3.5453e-01,\n",
              "           7.0066e-02, -4.6697e-01, -3.7250e-02, -1.7825e-02],\n",
              "         [-2.5842e-01, -1.5879e-03, -7.3816e-01,  3.3992e-04,  4.0950e-01,\n",
              "           6.5276e-02, -1.1635e-01, -1.8201e-01,  4.1028e-01, -2.1705e-01,\n",
              "           6.0742e-01, -2.0792e-02, -1.8707e-01, -2.1038e-01, -2.8120e-01,\n",
              "           2.1816e-01, -1.1572e-01, -5.2761e-01, -2.0959e-01,  3.1214e-01,\n",
              "          -1.3301e-01, -2.4530e-01,  7.6284e-02, -6.1614e-02]]],\n",
              "       grad_fn=<CatBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 630
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mha_out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5S1YOpyiCF3",
        "outputId": "cf301aa2-ba60-4441-d099-587d252225cc"
      },
      "id": "s5S1YOpyiCF3",
      "execution_count": 631,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 4, 24])"
            ]
          },
          "metadata": {},
          "execution_count": 631
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# copited from LLMs-from-scratch/ch03/\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert (d_out % num_heads == 0), \\\n",
        "            \"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer(\n",
        "            \"mask\",\n",
        "            torch.triu(torch.ones(context_length, context_length),\n",
        "                       diagonal=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "        # As in `CausalAttention`, for inputs where `num_tokens` exceeds `context_length`,\n",
        "        # this will result in errors in the mask creation further below.\n",
        "        # In practice, this is not a problem since the LLM (chapters 4-7) ensures that inputs\n",
        "        # do not exceed `context_length` before reaching this forward method.\n",
        "\n",
        "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
        "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
        "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
        "\n",
        "        # Original mask truncated to the number of tokens and converted to boolean\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        # Use the mask to fill attention scores\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
        "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec) # optional projection\n",
        "\n",
        "        return context_vec\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "batch_size, context_length, d_in = batches.shape\n",
        "d_out = 2\n",
        "mha = MultiHeadAttention(d_in, d_out, context_length, 0.0, num_heads=2)\n",
        "\n",
        "context_vecs = mha(batches)\n",
        "\n",
        "print(context_vecs)\n",
        "print(\"context_vecs.shape:\", context_vecs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4YgesXeitqg",
        "outputId": "6ca6bd07-1d05-43f8-c2b4-c3a6b59f9ff8"
      },
      "id": "r4YgesXeitqg",
      "execution_count": 632,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.0942,  0.1862],\n",
            "         [-0.0618,  0.1937],\n",
            "         [ 0.0984,  0.2526],\n",
            "         [ 0.0100,  0.2169]],\n",
            "\n",
            "        [[-0.0942,  0.1862],\n",
            "         [-0.0618,  0.1937],\n",
            "         [ 0.0984,  0.2526],\n",
            "         [ 0.0100,  0.2169]]], grad_fn=<ViewBackward0>)\n",
            "context_vecs.shape: torch.Size([2, 4, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mha = MultiHeadAtttention( d_in=8, d_out=6, num_heads=4, context_length=4, dropout=0 )\n",
        "mha_out = mha( batches )\n",
        "mha_out"
      ],
      "metadata": {
        "id": "AKQsMTbimtL_",
        "outputId": "13d1e42b-9d39-4b9d-a402-67403000a6da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "AKQsMTbimtL_",
      "execution_count": 634,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1.1008e-01,  9.3279e-01, -2.2153e-01,  1.2646e-01, -1.0283e-01,\n",
              "           6.7520e-01, -9.1997e-02, -1.0719e+00, -2.6806e-02,  9.1233e-01,\n",
              "           8.4830e-01,  9.2786e-01, -9.3980e-01,  1.2979e+00, -6.6498e-01,\n",
              "           9.9515e-02, -6.2438e-01,  9.0697e-01, -1.1210e-01,  6.1818e-02,\n",
              "          -7.8646e-01, -8.2610e-03, -4.8232e-01, -4.9239e-01],\n",
              "         [ 1.9144e-01,  8.6248e-01, -4.4032e-01, -5.1212e-02, -4.1459e-01,\n",
              "           4.7685e-01,  1.2396e-01, -8.5839e-01, -3.5714e-01,  8.1635e-01,\n",
              "           1.3785e-01,  7.1400e-02, -8.3076e-01,  7.3520e-01, -3.1956e-01,\n",
              "           3.1299e-01, -3.1264e-01,  9.7956e-01, -2.3090e-02, -3.4840e-01,\n",
              "          -5.3236e-01,  1.4260e-01, -2.9180e-01, -7.3608e-01],\n",
              "         [ 2.5967e-01,  2.7055e-01, -5.1644e-01,  2.4873e-01, -3.0062e-01,\n",
              "          -1.2209e-02,  3.3210e-01, -5.3176e-01, -3.5665e-01,  5.2701e-01,\n",
              "           4.6658e-01,  5.9160e-02, -6.5873e-01,  4.9429e-01, -2.2862e-03,\n",
              "           3.1935e-01,  7.0749e-04,  5.8875e-01, -2.9498e-01, -4.4280e-01,\n",
              "          -3.2781e-02,  1.3003e-01, -3.7479e-02, -2.9936e-01],\n",
              "         [ 1.6240e-01,  4.6102e-01, -3.2523e-01,  1.6312e-01, -3.1956e-01,\n",
              "           1.9859e-01,  2.2778e-01, -1.5389e-01, -2.7207e-01,  3.0692e-01,\n",
              "           1.7641e-01, -5.9144e-02, -2.8868e-01,  5.2895e-01, -1.6676e-01,\n",
              "           6.2690e-02, -2.8131e-02,  2.7096e-01,  1.0136e-01, -1.4557e-01,\n",
              "          -3.4931e-01,  2.4441e-01, -4.0906e-01, -5.5285e-02]],\n",
              "\n",
              "        [[-1.1008e-01,  9.3279e-01, -2.2153e-01,  1.2646e-01, -1.0283e-01,\n",
              "           6.7520e-01, -9.1997e-02, -1.0719e+00, -2.6806e-02,  9.1233e-01,\n",
              "           8.4830e-01,  9.2786e-01, -9.3980e-01,  1.2979e+00, -6.6498e-01,\n",
              "           9.9515e-02, -6.2438e-01,  9.0697e-01, -1.1210e-01,  6.1818e-02,\n",
              "          -7.8646e-01, -8.2610e-03, -4.8232e-01, -4.9239e-01],\n",
              "         [ 1.9144e-01,  8.6248e-01, -4.4032e-01, -5.1212e-02, -4.1459e-01,\n",
              "           4.7685e-01,  1.2396e-01, -8.5839e-01, -3.5714e-01,  8.1635e-01,\n",
              "           1.3785e-01,  7.1400e-02, -8.3076e-01,  7.3520e-01, -3.1956e-01,\n",
              "           3.1299e-01, -3.1264e-01,  9.7956e-01, -2.3090e-02, -3.4840e-01,\n",
              "          -5.3236e-01,  1.4260e-01, -2.9180e-01, -7.3608e-01],\n",
              "         [ 2.5967e-01,  2.7055e-01, -5.1644e-01,  2.4873e-01, -3.0062e-01,\n",
              "          -1.2209e-02,  3.3210e-01, -5.3176e-01, -3.5665e-01,  5.2701e-01,\n",
              "           4.6658e-01,  5.9160e-02, -6.5873e-01,  4.9429e-01, -2.2862e-03,\n",
              "           3.1935e-01,  7.0749e-04,  5.8875e-01, -2.9498e-01, -4.4280e-01,\n",
              "          -3.2781e-02,  1.3003e-01, -3.7479e-02, -2.9936e-01],\n",
              "         [ 1.6240e-01,  4.6102e-01, -3.2523e-01,  1.6312e-01, -3.1956e-01,\n",
              "           1.9859e-01,  2.2778e-01, -1.5389e-01, -2.7207e-01,  3.0692e-01,\n",
              "           1.7641e-01, -5.9144e-02, -2.8868e-01,  5.2895e-01, -1.6676e-01,\n",
              "           6.2690e-02, -2.8131e-02,  2.7096e-01,  1.0136e-01, -1.4557e-01,\n",
              "          -3.4931e-01,  2.4441e-01, -4.0906e-01, -5.5285e-02]]],\n",
              "       grad_fn=<CatBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 634
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mha_out.shape"
      ],
      "metadata": {
        "id": "YGrKx7IVm5YZ",
        "outputId": "cc44dc71-a0e4-4d4f-e0f3-2c5b8990f2f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "YGrKx7IVm5YZ",
      "execution_count": 635,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 4, 24])"
            ]
          },
          "metadata": {},
          "execution_count": 635
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}