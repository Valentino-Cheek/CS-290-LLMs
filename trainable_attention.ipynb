{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7c33a1a1",
      "metadata": {
        "id": "7c33a1a1"
      },
      "source": [
        "# Attention with trainable weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "id": "c78b079a",
      "metadata": {
        "id": "c78b079a"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "id": "d1c0c81b",
      "metadata": {
        "id": "d1c0c81b"
      },
      "outputs": [],
      "source": [
        "inputs = torch.nn.Embedding( 4, 8 )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = inputs.weight.data\n",
        "inputs"
      ],
      "metadata": {
        "id": "EGWp0DcrxAYS",
        "outputId": "03f93b94-4cdb-4051-d9fb-70dd077d3eb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "EGWp0DcrxAYS",
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.5546,  0.2966,  2.0589, -0.9608,  1.1342, -0.3602,  0.3127, -0.3441],\n",
              "        [-1.8143, -1.9086,  1.5761, -0.0748,  1.0284,  0.8431, -0.3166,  0.4879],\n",
              "        [-2.3368, -0.8830, -0.5530,  1.1507,  0.5392,  1.2049,  1.1838, -0.0752],\n",
              "        [-1.7607, -0.9615,  0.3583, -2.0808, -1.0154, -0.7016, -0.2094, -0.8293]])"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set dimension\n",
        "d_in = 8\n",
        "d_out = 6\n",
        "\n",
        "# create weight matrices\n",
        "w_query = torch.nn.Parameter( torch.randn( d_in, d_out ), requires_grad=False )\n",
        "w_key = torch.nn.Parameter( torch.randn( d_in, d_out ), requires_grad=False )\n",
        "w_value = torch.nn.Parameter( torch.randn( d_in, d_out ), requires_grad=False )\n"
      ],
      "metadata": {
        "id": "BV1AyTvYxCt8"
      },
      "id": "BV1AyTvYxCt8",
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# choose and input vector and tranfrom it into our query vector using w_query\n",
        "query = inputs[2] @ w_query\n",
        "query"
      ],
      "metadata": {
        "id": "giMsI6IoyWTl",
        "outputId": "939ed081-6627-4a16-b6da-88586b86f918",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "giMsI6IoyWTl",
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.5475, -5.5059, -4.9801, -8.9749,  1.7650, -2.8583])"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate attention scores using the keys generated by w_key\n",
        "keys = inputs @ w_key\n",
        "values = inputs @ w_value\n",
        "print(\"Values: \", values, \"\\nKeys: \", keys)"
      ],
      "metadata": {
        "id": "6C8AR2qzy3MI",
        "outputId": "5e686d14-2ef2-4c3c-ccf0-fb848c76ba39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "6C8AR2qzy3MI",
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Values:  tensor([[ 4.2913, -0.9399,  2.7514,  1.3161,  2.1229, -5.5799],\n",
            "        [-4.2806, -4.3206,  6.4974,  4.4086,  0.1625, -4.3899],\n",
            "        [-0.6404, -1.2269,  1.1270,  3.6036,  0.9804, -0.5700],\n",
            "        [-4.0006, -2.8639,  6.1219,  1.1201, -6.6592,  4.3211]]) \n",
            "Keys:  tensor([[-0.9820, -4.2075, -0.2588, -0.8410,  0.8486, -1.2789],\n",
            "        [-2.2700,  3.0331, -1.1149,  1.8968,  3.6503, -3.3202],\n",
            "        [-1.9354,  4.8751, -3.1151,  5.3309,  2.1982, -0.5466],\n",
            "        [ 2.0072,  3.4482,  6.0506,  1.9756,  0.8990, -3.9215]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_scores = query @ keys.T\n",
        "attention_scores"
      ],
      "metadata": {
        "id": "dbIXaFAuzI8-",
        "outputId": "a6531191-e8c7-43d0-a720-1dd6e6d716ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "dbIXaFAuzI8-",
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 38.6757,  -8.7250, -50.7352, -57.1592])"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# attention_weights = attention_scores.softmax(dim = -1)\n",
        "\n",
        "attention_weights = torch.softmax(attention_scores / keys.shape[-1]**0.5, dim=-1 )\n",
        "attention_weights"
      ],
      "metadata": {
        "id": "ZojH88rW0FUZ",
        "outputId": "7d9854e1-c262-40e8-f068-305a2fc3fea8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ZojH88rW0FUZ",
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0000e+00, 3.9433e-09, 1.4043e-16, 1.0197e-17])"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights.sum()"
      ],
      "metadata": {
        "id": "K7y_eHzk0hrh",
        "outputId": "a2ea3dc1-eebd-4563-d8c4-67a608150bd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "K7y_eHzk0hrh",
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_vector = attention_weights @ values\n",
        "context_vector"
      ],
      "metadata": {
        "id": "QcX7_Lr407D2",
        "outputId": "a29a0cfe-4dcd-4f56-876f-60a9713de755",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "QcX7_Lr407D2",
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 4.2913, -0.9399,  2.7514,  1.3161,  2.1229, -5.5799])"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "9CJK6c8p090W"
      },
      "id": "9CJK6c8p090W",
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleAttention( nn.Module ):\n",
        "  def __init__( self, d_in, d_out ):\n",
        "    super().__init__()\n",
        "    # create weight matrices\n",
        "    self.W_query = torch.nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
        "    self.W_key = torch.nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
        "    self.W_value = torch.nn.Parameter( torch.rand( d_in, d_out ), requires_grad=False )\n",
        "\n",
        "  # x = embedding vectors (inputs)\n",
        "  def forward(self, x):\n",
        "    query = x @ self.W_query\n",
        "    keys = x @ self.W_key\n",
        "    values = x @ self.W_value\n",
        "    attention_scores = query @ keys.T\n",
        "    weights = torch.softmax(attention_scores / keys.shape[-1]**0.5, dim=-1 )\n",
        "    context_vector = weights @ values\n",
        "    return context_vector\n",
        "\n"
      ],
      "metadata": {
        "id": "rmqohDO9EwKF"
      },
      "id": "rmqohDO9EwKF",
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# how to use, instantiate an instance of it\n",
        "simple = SimpleAttention( d_in=8, d_out=6 )"
      ],
      "metadata": {
        "id": "8dPmmHSkGedw"
      },
      "id": "8dPmmHSkGedw",
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simple.W_value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLWq9QVCGjbt",
        "outputId": "01b3c694-daa5-4dec-8fb4-2f105339d3c5"
      },
      "id": "sLWq9QVCGjbt",
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[0.3606, 0.4550, 0.8046, 0.3757, 0.7438, 0.2470],\n",
              "        [0.7580, 0.7419, 0.1634, 0.2725, 0.3278, 0.0818],\n",
              "        [0.4613, 0.2523, 0.7435, 0.0907, 0.2169, 0.4255],\n",
              "        [0.3549, 0.2882, 0.0194, 0.5397, 0.7751, 0.6892],\n",
              "        [0.9210, 0.0218, 0.9647, 0.4730, 0.6370, 0.3097],\n",
              "        [0.9146, 0.2590, 0.0981, 0.7211, 0.5695, 0.6908],\n",
              "        [0.4844, 0.3496, 0.7356, 0.2102, 0.4970, 0.6801],\n",
              "        [0.5970, 0.4330, 0.3571, 0.5969, 0.0214, 0.2182]])"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_vectors = simple(inputs)\n",
        "context_vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fo3YvoTGmDf",
        "outputId": "5f2dd176-cb8b-4501-e4dc-8c42be01eeae"
      },
      "id": "5fo3YvoTGmDf",
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.2834, -0.0511,  1.6461,  0.3132,  0.5517,  0.9596],\n",
              "        [ 0.7401, -0.8125, -0.3155,  0.5519,  0.1722,  1.3695],\n",
              "        [ 0.9074, -0.5208,  0.9765,  0.2446,  0.1340,  0.9078],\n",
              "        [-4.1104, -2.6600, -2.8465, -3.5393, -4.3281, -2.9177]])"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleAttention2( nn.Module ):\n",
        "  def __init__( self, d_in, d_out ):\n",
        "    super().__init__()\n",
        "    # create weight matrices\n",
        "    self.W_query = nn.Linear( d_in, d_out, bias=False )\n",
        "    self.W_key = nn.Linear( d_in, d_out, bias=False )\n",
        "    self.W_value = nn.Linear( d_in, d_out, bias=False )\n",
        "\n",
        "  # x = embedding vectors (inputs)\n",
        "  def forward(self, x):\n",
        "    query = self.W_query( x )\n",
        "    keys = self.W_key( x )\n",
        "    values = self.W_value( x )\n",
        "    attention_scores = query @ keys.T\n",
        "    weights = torch.softmax(attention_scores / keys.shape[-1]**0.5, dim=-1 )\n",
        "    context_vector = weights @ values\n",
        "    return context_vector"
      ],
      "metadata": {
        "id": "jkfLRAbqGyZ9"
      },
      "id": "jkfLRAbqGyZ9",
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# how to use, instantiate an instance of it\n",
        "simple = SimpleAttention2( d_in=8, d_out=6 )\n"
      ],
      "metadata": {
        "id": "f7MsCXlAIsAO"
      },
      "id": "f7MsCXlAIsAO",
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simple.W_value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sChX5MKRIvD-",
        "outputId": "87e2b955-c31d-4a04-bfdc-86f1ac3a4514"
      },
      "id": "sChX5MKRIvD-",
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=8, out_features=6, bias=False)"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_vectors = simple(inputs)\n",
        "context_vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ETDYdLZI2QN",
        "outputId": "91d65f80-9d8a-43a9-ba50-766b6905c40e"
      },
      "id": "_ETDYdLZI2QN",
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.3151, -0.0453,  0.8171, -0.5821,  0.0013, -0.3779],\n",
              "        [-0.4395,  0.1396,  0.6292, -0.2068,  0.1724, -0.3179],\n",
              "        [-0.4181,  0.1646,  0.7088, -0.2527,  0.1108, -0.2131],\n",
              "        [-0.3831,  0.0844,  0.8050, -0.4328,  0.0461, -0.2671]],\n",
              "       grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the problem wit h this is that each context vector uses infortmation from ALL of the embedding vectors\n",
        "# om practice, wer should only use the information about the preceding embedding vectors\n",
        "# to accomplish this, we'll implement causal attention AKA masked attention"
      ],
      "metadata": {
        "id": "HYxGgL0dI3sP"
      },
      "id": "HYxGgL0dI3sP",
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleAttention2( nn.Module ):\n",
        "  def __init__( self, d_in, d_out ):\n",
        "    super().__init__()\n",
        "    # create weight matrices\n",
        "    self.W_query = nn.Linear( d_in, d_out, bias=False )\n",
        "    self.W_key = nn.Linear( d_in, d_out, bias=False )\n",
        "    self.W_value = nn.Linear( d_in, d_out, bias=False )\n",
        "\n",
        "  # x = embedding vectors (inputs)\n",
        "  def forward(self, x):\n",
        "    query = self.W_query( x )\n",
        "    keys = self.W_key( x )\n",
        "    values = self.W_value( x )\n",
        "    attention_scores = query @ keys.T\n",
        "    weights = torch.softmax(attention_scores / keys.shape[-1]**0.5, dim=-1 )\n",
        "    context_vector = weights @ values\n",
        "    return weights"
      ],
      "metadata": {
        "id": "yihDtot8dTLs"
      },
      "id": "yihDtot8dTLs",
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simple = SimpleAttention2( d_in=8, d_out=6 )\n",
        "weights = simple( inputs )\n",
        "weights"
      ],
      "metadata": {
        "id": "GQavVLtQditY",
        "outputId": "21ca7fbe-e7c4-48c0-af5e-d4e9bcb0168a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "GQavVLtQditY",
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2307, 0.2837, 0.2586, 0.2270],\n",
              "        [0.2975, 0.2660, 0.2691, 0.1674],\n",
              "        [0.3651, 0.2201, 0.2732, 0.1417],\n",
              "        [0.3673, 0.2139, 0.2436, 0.1753]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#already normalized\n",
        "weights.sum(dim= -1)"
      ],
      "metadata": {
        "id": "YhQ2lau0dr0X",
        "outputId": "f7d9f73b-8e9c-4130-e818-9f7671bab828",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "YhQ2lau0dr0X",
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Masking Method 1\n",
        "simple_mask = torch.tril( torch.ones(weights.shape[0],weights.shape[0]))\n",
        "simple_mask"
      ],
      "metadata": {
        "id": "yI4jQ5Xrd_3B",
        "outputId": "cf46d0b8-3b4c-4576-99ba-a4ef8a714acc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "yI4jQ5Xrd_3B",
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0.],\n",
              "        [1., 1., 0., 0.],\n",
              "        [1., 1., 1., 0.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# multiply to get the coordinate by coordinate product, NOT dot product\n",
        "masked_weights = weights * simple_mask\n",
        "masked_weights"
      ],
      "metadata": {
        "id": "DFwEX_i0eq_6",
        "outputId": "46fb2baa-6cf2-4175-8f31-05d1d334248e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "DFwEX_i0eq_6",
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2307, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2975, 0.2660, 0.0000, 0.0000],\n",
              "        [0.3651, 0.2201, 0.2732, 0.0000],\n",
              "        [0.3673, 0.2139, 0.2436, 0.1753]], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now we need to normaliz the masked_weights so that each row has a sum 1\n",
        "row_sums = masked_weights.sum(dim=-1, keepdim=True)\n",
        "row_sums"
      ],
      "metadata": {
        "id": "8JxuevCRe8XI",
        "outputId": "b40258b6-43f6-4f30-9abe-b0b172eb0df4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "8JxuevCRe8XI",
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2307],\n",
              "        [0.5635],\n",
              "        [0.8583],\n",
              "        [1.0000]], grad_fn=<SumBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_weights_norm = masked_weights / row_sums\n",
        "print(masked_weights_norm)\n",
        "print(masked_weights_norm.sum(dim=-1))"
      ],
      "metadata": {
        "id": "D5KVzCecfvrX",
        "outputId": "af3ab0ef-d494-4fe0-8c58-d4e9e4a19c90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "D5KVzCecfvrX",
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.5280, 0.4720, 0.0000, 0.0000],\n",
            "        [0.4254, 0.2564, 0.3182, 0.0000],\n",
            "        [0.3673, 0.2139, 0.2436, 0.1753]], grad_fn=<DivBackward0>)\n",
            "tensor([1., 1., 1., 1.], grad_fn=<SumBackward1>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Masking method 2\n",
        "mask = torch.triu(torch.ones(weights.shape[0], weights.shape[0]), diagonal =1)\n",
        "mask"
      ],
      "metadata": {
        "id": "nB_aMu4df3WP",
        "outputId": "3249af2b-c3f1-42d8-e007-3e4339ad464d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "nB_aMu4df3WP",
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1., 1., 1.],\n",
              "        [0., 0., 1., 1.],\n",
              "        [0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# can use mask == 1 or mask.bool()\n",
        "weights_masked = weights.masked_fill(mask == 1, -torch.inf)\n",
        "weights_masked"
      ],
      "metadata": {
        "id": "S5vi0z2PhDzI",
        "outputId": "ac613663-5d25-4b73-efc6-4e40f2af5a99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "S5vi0z2PhDzI",
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2307,   -inf,   -inf,   -inf],\n",
              "        [0.2975, 0.2660,   -inf,   -inf],\n",
              "        [0.3651, 0.2201, 0.2732,   -inf],\n",
              "        [0.3673, 0.2139, 0.2436, 0.1753]], grad_fn=<MaskedFillBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights_masked_norm = torch.softmax(weights_masked, dim=-1)\n",
        "weights_masked_norm\n",
        "print(weights_masked_norm.sum(dim=-1))"
      ],
      "metadata": {
        "id": "UTzLv__ahfKq",
        "outputId": "6b0f74db-d41f-4738-8b16-314a2103492e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "UTzLv__ahfKq",
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## DROPOUT - avoiding overfitting by randomly leaving out data\n",
        "# idea : randomly select some data to leave out to avoid overfitting\n",
        "dropout = nn.Dropout(p=0.5) # 50% dropout weight\n",
        "dropout( inputs )"
      ],
      "metadata": {
        "id": "46w4BDdMkWjf",
        "outputId": "8fe6c988-ce14-42ab-be22-159af4cd3287",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "46w4BDdMkWjf",
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.5933,  0.0000, -0.0000,  2.2683, -0.0000,  0.6253, -0.6882],\n",
              "        [-0.0000, -3.8171,  0.0000, -0.1497,  2.0568,  0.0000, -0.0000,  0.9758],\n",
              "        [-4.6736, -0.0000, -0.0000,  2.3013,  1.0784,  2.4098,  2.3676, -0.1504],\n",
              "        [-3.5214, -0.0000,  0.7165, -4.1616, -0.0000, -1.4032, -0.4187, -1.6586]])"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we need to be able to give our LLM batches of input\n",
        "# for example:\n",
        "batches = torch.stack((inputs, inputs), dim=0)\n",
        "print(batches)\n",
        "torch.stack?"
      ],
      "metadata": {
        "id": "DF4op0SbjUsJ",
        "outputId": "d9c19f30-4e7e-4714-969f-89069dd48e0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "DF4op0SbjUsJ",
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.5546,  0.2966,  2.0589, -0.9608,  1.1342, -0.3602,  0.3127,\n",
            "          -0.3441],\n",
            "         [-1.8143, -1.9086,  1.5761, -0.0748,  1.0284,  0.8431, -0.3166,\n",
            "           0.4879],\n",
            "         [-2.3368, -0.8830, -0.5530,  1.1507,  0.5392,  1.2049,  1.1838,\n",
            "          -0.0752],\n",
            "         [-1.7607, -0.9615,  0.3583, -2.0808, -1.0154, -0.7016, -0.2094,\n",
            "          -0.8293]],\n",
            "\n",
            "        [[ 0.5546,  0.2966,  2.0589, -0.9608,  1.1342, -0.3602,  0.3127,\n",
            "          -0.3441],\n",
            "         [-1.8143, -1.9086,  1.5761, -0.0748,  1.0284,  0.8431, -0.3166,\n",
            "           0.4879],\n",
            "         [-2.3368, -0.8830, -0.5530,  1.1507,  0.5392,  1.2049,  1.1838,\n",
            "          -0.0752],\n",
            "         [-1.7607, -0.9615,  0.3583, -2.0808, -1.0154, -0.7016, -0.2094,\n",
            "          -0.8293]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batches.shape"
      ],
      "metadata": {
        "id": "diGeJ_Wbj4OO",
        "outputId": "b9b16fb9-533f-4629-9fb6-bcf6d4684bd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "diGeJ_Wbj4OO",
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 4, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this class needs to hand batches of input\n",
        "\n",
        "class CausalAttention( nn.Module )\n",
        "  def __init__( self, d_in, d_out, context_length, dropout, qky_bias=False ):\n",
        "    super().__init__()\n",
        "    # create weight matrices\n",
        "    self.W_query = nn.Linear( d_in, d_out, bias=False )\n",
        "    self.W_key = nn.Linear( d_in, d_out, bias=False )\n",
        "    self.W_value = nn.Linear( d_in, d_out, bias=False )\n",
        "    self.dropout = nn.Dropout( dropout )\n",
        "\n",
        "  # x = embedding vectors (inputs)\n",
        "  def forward(self, x):\n",
        "    query = self.W_query( x )\n",
        "    keys = self.W_key( x )\n",
        "    values = self.W_value( x )\n",
        "    attention_scores = query @ keys.T\n",
        "    weights = torch.softmax(attention_scores / keys.shape[-1]**0.5, dim=-1 )\n",
        "    context_vector = weights @ values\n",
        "    return context_vector"
      ],
      "metadata": {
        "id": "k2OzXqWFiGun"
      },
      "id": "k2OzXqWFiGun",
      "execution_count": 167,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}