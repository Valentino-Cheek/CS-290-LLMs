{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_dR5-0pG_0CT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "TxTde7eyBO7C"
      },
      "outputs": [],
      "source": [
        "# needed to pull txt file from github\n",
        "import os\n",
        "import urllib.request\n",
        "\n",
        "if not os.path.exists(\"one-foggy-night.txt\"):\n",
        "    url = (\"https://raw.githubusercontent.com/Valentino-Cheek/CS-290-LLMs/refs/heads/main/one-foggy-night.txt\")\n",
        "    file_path = \"one-foggy-night.txt\"\n",
        "    urllib.request.urlretrieve(url, file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQuVeLeXk0Hj",
        "outputId": "6bcf0a71-7c0b-4989-df4d-9c2e55f9b9bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A PLUME of smoke drifted under the great glass dom\n"
          ]
        }
      ],
      "source": [
        "# read text file and print some text\n",
        "with open (\"one-foggy-night.txt\", \"r\" ) as f:\n",
        "    raw_text = f.read()\n",
        "\n",
        "print (raw_text[:50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ebysZGe3k4SZ"
      },
      "outputs": [],
      "source": [
        "# initizating the tokenizer and encoding the text\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "enc_text = tokenizer.encode(raw_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "bC7uOhTqlIhd"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        # Tokenize the entire text\n",
        "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "        assert len(token_ids) > max_length, \"Number of tokenized inputs must at least be equal to max_length+1\"\n",
        "\n",
        "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i + max_length]\n",
        "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ZtW-ohbrmA0o"
      },
      "outputs": [],
      "source": [
        "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
        "                         stride=128, shuffle=True, drop_last=True,\n",
        "                         num_workers=0):\n",
        "\n",
        "    # Initialize the tokenizer\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "    # Create dataset\n",
        "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "\n",
        "    # Create dataloader\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        drop_last=drop_last,\n",
        "        num_workers=num_workers\n",
        "    )\n",
        "\n",
        "    return dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgk4A-dlmDAW",
        "outputId": "4a73928a-b5bc-44ca-d7fc-8ad26882ae2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tensor([[   32,  9297, 38340,   286]]), tensor([[ 9297, 38340,   286,  7523]])]\n",
            "[tensor([[ 9297, 38340,   286,  7523]]), tensor([[38340,   286,  7523, 38648]])]\n"
          ]
        }
      ],
      "source": [
        "# a dataloader with a max length of 4 and a stride of 1\n",
        "dataloader = create_dataloader_v1(\n",
        "    raw_text, batch_size=1, max_length=4, stride=1, shuffle=False\n",
        ")\n",
        "\n",
        "data_iter = iter(dataloader)\n",
        "first_batch = next(data_iter)\n",
        "print(first_batch)\n",
        "second_batch = next(data_iter)\n",
        "\n",
        "print(second_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hJ1mvtVmKeV",
        "outputId": "75082dc9-02c0-4410-d616-4c55245c1235"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inputs:\n",
            " tensor([[   32,  9297, 38340,   286,  7523, 38648],\n",
            "        [  739,   262,  1049,  5405, 29500,   286]])\n",
            "\n",
            "Targets:\n",
            " tensor([[ 9297, 38340,   286,  7523, 38648,   739],\n",
            "        [  262,  1049,  5405, 29500,   286,  3454]])\n"
          ]
        }
      ],
      "source": [
        "# a data loader with a batch size of 2, max length of 6 and stride of 6\n",
        "dataloader = create_dataloader_v1(\n",
        "    raw_text, batch_size=2, max_length=6, stride=6, shuffle=False\n",
        ")\n",
        "data_iter = iter(dataloader)\n",
        "\n",
        "# organize the data into inputs and targets\n",
        "inputs, targets = next(data_iter)\n",
        "print(\"Inputs:\\n\", inputs)\n",
        "print(\"\\nTargets:\\n\", targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTwLyfNnmcYq",
        "outputId": "5f9fb68b-b039-443e-9389-63ab59f58ee1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inputs:\n",
            " tensor([[   32,  9297, 38340,   286],\n",
            "        [ 7523, 38648,   739,   262],\n",
            "        [ 1049,  5405, 29500,   286],\n",
            "        [ 3454,   363, 17913,  9327]])\n",
            "\n",
            "Targets:\n",
            " tensor([[ 9297, 38340,   286,  7523],\n",
            "        [38648,   739,   262,  1049],\n",
            "        [ 5405, 29500,   286,  3454],\n",
            "        [  363, 17913,  9327,   355]])\n"
          ]
        }
      ],
      "source": [
        "# a data loader with a batch size, max length and stride of 4\n",
        "dataloader = create_dataloader_v1(\n",
        "    raw_text, batch_size=4, max_length=4, stride=4, shuffle=False\n",
        ")\n",
        "data_iter = iter(dataloader)\n",
        "\n",
        "# organize the data into inputs and targets\n",
        "inputs, targets = next(data_iter)\n",
        "print(\"Inputs:\\n\", inputs)\n",
        "print(\"\\nTargets:\\n\", targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftscBqf0pamX",
        "outputId": "57dc65f2-50b3-4504-9787-dcf86b6d64eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A PLUME of\n",
            " smoke drifted under the\n",
            " great glass dome of\n",
            " Slagborough Station\n",
            " PLUME of smoke\n",
            " drifted under the great\n",
            " glass dome of Sl\n",
            "agborough Station as\n"
          ]
        }
      ],
      "source": [
        "# iterating through the tensors, looking at the words rather than the tokens\n",
        "for row in inputs:\n",
        "    print(tokenizer.decode ( row.tolist()))\n",
        "# iterating through the tensors, looking at the words rather than the tokens\n",
        "for row in targets:\n",
        "    print(tokenizer.decode ( row.tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dN-jrltoq8It",
        "outputId": "f038bc5c-272a-484e-8e37-4f796da4f366"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.2827,  0.5502,  1.5729,  0.5980],\n",
            "        [-0.6337,  0.4333, -1.5340, -0.5352],\n",
            "        [ 0.6825, -0.4818, -0.4992,  0.8141],\n",
            "        [ 1.1403,  0.9638, -0.6608,  0.3767],\n",
            "        [ 1.9081,  0.7504, -0.0339,  0.5945],\n",
            "        [-0.4364, -0.1453,  0.4935, -1.0386],\n",
            "        [-0.7417, -0.7000,  0.4368,  0.7527],\n",
            "        [-1.1524, -0.3119,  0.7796,  1.0384]], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "# create an embedding layer with a vocab size of 8 and an output dimension of 4\n",
        "\n",
        "# Embedding is essential in the creation of LLMs because it allows the model\n",
        "# to have parameters that are trainable.\n",
        "\n",
        "#The embedding creates the ability for the model to interpret contextual\n",
        "#information through training.\n",
        "\n",
        "# Without it the model would not be able to interpret the english language,\n",
        "# embedding creates numbers that can be adjusted based on the raw words inputed.\n",
        "\n",
        "# This step allows (or is the foundation of ) the training and \"learning\" of a LLM\n",
        "vocab_size = 8\n",
        "output_dim = 4\n",
        "\n",
        "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
        "print(embedding_layer.weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUdgg64ftxli",
        "outputId": "37f779e5-e0b2-4dff-ab5a-fa3708c9f720"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.2827,  0.5502,  1.5729,  0.5980],\n",
            "        [-0.6337,  0.4333, -1.5340, -0.5352],\n",
            "        [ 0.6825, -0.4818, -0.4992,  0.8141],\n",
            "        [ 1.1403,  0.9638, -0.6608,  0.3767],\n",
            "        [ 1.9081,  0.7504, -0.0339,  0.5945],\n",
            "        [-0.4364, -0.1453,  0.4935, -1.0386],\n",
            "        [-0.7417, -0.7000,  0.4368,  0.7527],\n",
            "        [-1.1524, -0.3119,  0.7796,  1.0384]])\n"
          ]
        }
      ],
      "source": [
        "# remove the requires_grad=True\n",
        "inputs = embedding_layer.weight.data\n",
        "print(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o89NJZxXylWw",
        "outputId": "94986137-79c9-4373-f227-269e6e013f77"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 3.2142, -2.3152, -0.7563, -0.6061,  0.1757,  0.1985,  0.9617,  2.0013],\n",
              "        [-2.3152,  3.2288, -0.3113,  0.5070, -1.1503,  0.0125, -0.9061, -1.1564],\n",
              "        [-0.7563, -0.3113,  1.6099,  0.9504,  1.4417, -1.3197,  0.2257, -0.1800],\n",
              "        [-0.6061,  0.5070,  0.9504,  2.8077,  3.1454, -1.3550, -1.5255, -1.7386],\n",
              "        [ 0.1757, -1.1503,  1.4417,  3.1454,  4.5587, -1.5759, -1.5078, -1.8420],\n",
              "        [ 0.1985,  0.0125, -1.3197, -1.3550, -1.5759,  1.5337, -0.1407, -0.1455],\n",
              "        [ 0.9617, -0.9061,  0.2257, -1.5255, -1.5078, -0.1407,  1.7973,  2.1951],\n",
              "        [ 2.0013, -1.1564, -0.1800, -1.7386, -1.8420, -0.1455,  2.1951,  3.1112]])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get all of the attention scores by matrix multiplication\n",
        "# transpose in order to create a similarity matrix\n",
        "attention_scores = inputs @ inputs.T\n",
        "attention_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJeHCShuzoJI",
        "outputId": "1afdd77a-1250-4a27-9236-def80b9bd60f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.6476, 0.0026, 0.0122, 0.0142, 0.0310, 0.0317, 0.0681, 0.1926],\n",
              "        [0.0033, 0.8476, 0.0246, 0.0557, 0.0106, 0.0340, 0.0136, 0.0106],\n",
              "        [0.0305, 0.0476, 0.3254, 0.1682, 0.2750, 0.0174, 0.0815, 0.0543],\n",
              "        [0.0121, 0.0367, 0.0572, 0.3663, 0.5134, 0.0057, 0.0048, 0.0039],\n",
              "        [0.0095, 0.0025, 0.0338, 0.1858, 0.7636, 0.0017, 0.0018, 0.0013],\n",
              "        [0.1307, 0.1085, 0.0286, 0.0276, 0.0222, 0.4967, 0.0931, 0.0926],\n",
              "        [0.1270, 0.0196, 0.0609, 0.0106, 0.0107, 0.0422, 0.2930, 0.4360],\n",
              "        [0.1797, 0.0076, 0.0203, 0.0043, 0.0038, 0.0210, 0.2181, 0.5452]])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# normalize the attention scores\n",
        "# soft max also highlights more important tokens, causes the model to \"focus\" on the most relevant tokens\n",
        "attention_weights = torch.softmax( attention_scores, dim = -1)\n",
        "attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYRb1rg8z_mK",
        "outputId": "ef142fab-69af-4e9b-dfd9-730434a91065"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check that each row of the normalized scores add up to 1, validating that softmax and the matrix multiplication went properly\n",
        "attention_weights.sum(axis = -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gipCkzQ0WCK",
        "outputId": "001b4545-2380-4165-d512-f3661e98f0b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.3872,  0.2762,  1.1936,  0.6379],\n",
              "        [-0.4746,  0.4012, -1.3135, -0.4184],\n",
              "        [ 0.7691,  0.1727, -0.2214,  0.5842],\n",
              "        [ 1.3991,  0.7279, -0.3173,  0.4791],\n",
              "        [ 1.6842,  0.7403, -0.1518,  0.5568],\n",
              "        [-0.4049, -0.0178,  0.3638, -0.2826],\n",
              "        [-0.7124, -0.2799,  0.6207,  0.7548],\n",
              "        [-0.8287, -0.2263,  0.7885,  0.8322]])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# calculate the context vectors based on the attention weights and inputs\n",
        "context_vectors = attention_weights @ inputs\n",
        "context_vectors"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPUQFx9XSPhEOtoNcMLdTHO",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
